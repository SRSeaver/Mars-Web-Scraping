{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to instantiate a browser object using chromdriver\n",
    "def init_browser():\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    return Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of NASA page\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# Instantiate the browser, store in browser variable\n",
    "browser = init_browser()\n",
    "# Go to url using .visit\n",
    "browser.visit(url)\n",
    "# Force a pause to give the articles a chance to load\n",
    "time.sleep(2)\n",
    "# Scrape the html text\n",
    "html = browser.html\n",
    "# The browser is still open so quit browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautifulsoup object\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Retrieve all the parent divs of news titles and paragraphs\n",
    "result = soup.find('ul', class_='item_list')\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyond Mars, the Mini MarCO Spacecraft Fall Silent\n",
      "The first CubeSat mission to deep space may have reached their limit, but they could inspire future NASA missions.\n"
     ]
    }
   ],
   "source": [
    "# Dig through the results to get the first slide, title, and paragraph\n",
    "slide = result.find('div', class_='list_text')\n",
    "title = slide.find('div', class_='content_title').text\n",
    "paragraph = slide.find('div', class_='article_teaser_body').text\n",
    "\n",
    "print(title)\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for JPL Featured Space Image\n",
    "mars_images_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "# Instantiate the browser, store in browser variable\n",
    "browser = init_browser()\n",
    "# Go to browser with .visit\n",
    "browser.visit(mars_images_url)\n",
    "# Force a pause to give page a chance to completely load\n",
    "time.sleep(2)\n",
    "# Scrape the images\n",
    "images_html = browser.html\n",
    "# The browser is still open so quit browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA16884-1920x1200.jpg'\n"
     ]
    }
   ],
   "source": [
    "# Beautifulsoup object, \n",
    "image_soup = bs(images_html, 'html.parser')\n",
    "# print(image_soup)\n",
    "\n",
    "# Narrow down the image_soup and dig through to the feature image \n",
    "image_result = image_soup.find('div', class_='carousel_items').find('article')['style']\n",
    "# print(image_result)\n",
    "# split the returned string to get only the relevant part for the url\n",
    "image_url = image_result.split(\"'\")[1]\n",
    "\n",
    "# Combine \"https://www.jpl.nasa.gov\" and the image_url to create the featured image url\n",
    "featured_image_url = f\"'https://www.jpl.nasa.gov{image_url}'\"\n",
    "print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for Mars weather tweet\n",
    "mars_tweet_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "# Instantiate the browser, store in browser variable\n",
    "browser = init_browser()\n",
    "# Go to browser with .visit\n",
    "browser.visit(mars_tweet_url)\n",
    "# Force a pause to give page a chance to completely load\n",
    "time.sleep(2)\n",
    "# Scrape the images\n",
    "tweets_html = browser.html\n",
    "# The browser is still open so quit browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol 2310 (2019-02-04), high -6C/21F, low -75C/-102F, pressure at 8.15 hPa, daylight 06:47-18:53pic.twitter.com/oRYhGR1P9C\n"
     ]
    }
   ],
   "source": [
    "tweet_soup = bs(tweets_html, 'html.parser')\n",
    "# print(tweet_soup)\n",
    "\n",
    "# Get the latest Mars weather tweet and get the weather text\n",
    "weather_result = tweet_soup.find('div', class_='tweet')\n",
    "# print(weather_result)\n",
    "weather = weather_result.find('p', class_='tweet-text').text\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Value</th>    </tr>    <tr>      <th>Fact</th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Equatorial Diameter:</th>      <td>6,792 km</td>    </tr>    <tr>      <th>Polar Diameter:</th>      <td>6,752 km</td>    </tr>    <tr>      <th>Mass:</th>      <td>6.42 x 10^23 kg (10.7% Earth)</td>    </tr>    <tr>      <th>Moons:</th>      <td>2 (Phobos &amp; Deimos)</td>    </tr>    <tr>      <th>Orbit Distance:</th>      <td>227,943,824 km (1.52 AU)</td>    </tr>    <tr>      <th>Orbit Period:</th>      <td>687 days (1.9 years)</td>    </tr>    <tr>      <th>Surface Temperature:</th>      <td>-153 to 20 Â°C</td>    </tr>    <tr>      <th>First Record:</th>      <td>2nd millennium BC</td>    </tr>    <tr>      <th>Recorded By:</th>      <td>Egyptian astronomers</td>    </tr>  </tbody></table>\n"
     ]
    }
   ],
   "source": [
    "# Url for Mars facts\n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# Use pandas to get the tables from the url\n",
    "mars_facts = pd.read_html(mars_facts_url)\n",
    "facts_df = mars_facts[0]\n",
    "\n",
    "# Add column names\n",
    "facts_df.columns = ['Fact', 'Value']\n",
    "facts_df = facts_df.set_index(\"Fact\")\n",
    "\n",
    "# Use Pandas to convert the data to a HTML table string\n",
    "facts_html_table = facts_df.to_html()\n",
    "facts_html_table = facts_html_table.replace('\\n', '')\n",
    "facts_html_table\n",
    "\n",
    "print(facts_html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for hemispheres\n",
    "hemispheres_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "# Instantiate the browser, store in browser variable\n",
    "browser = init_browser()\n",
    "# Go to browser with .visit\n",
    "browser.visit(hemispheres_url)\n",
    "# Scrape the page\n",
    "hemispheres_html = browser.html\n",
    "\n",
    "# Get the list of partial hrefs for each link\n",
    "hemisphere_soup = bs(hemispheres_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Cerberus Hemispher', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}\n",
      "{'title': 'Schiaparelli Hemispher', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}\n",
      "{'title': 'Syrtis Major Hemispher', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}\n",
      "{'title': 'Valles Marineris Hemispher', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary to hold titles and urls\n",
    "hemisphere_dicts = []\n",
    "\n",
    "# Get the links to click\n",
    "buttons = hemisphere_soup.find_all('h3')\n",
    "# print(buttons)\n",
    "\n",
    "# Loop through the buttons to get the titles and url links\n",
    "for button in buttons:\n",
    "    hemisphere_dict = {}\n",
    "    \n",
    "    t = button.get_text()\n",
    "    title = t.strip(' Enhanced')\n",
    "    hemisphere_dict['title'] = title\n",
    "    browser.click_link_by_partial_text(t)\n",
    "    time.sleep(2)\n",
    "    url = browser.find_link_by_partial_href('download')['href']\n",
    "    time.sleep(2)\n",
    "    hemisphere_dict['img_url'] = url\n",
    "    hemisphere_dicts.append(hemisphere_dict)\n",
    "    browser.visit(hemispheres_url)\n",
    "    \n",
    "# The browser is still open so quit browser\n",
    "browser.quit()\n",
    "    \n",
    "    \n",
    "for dct in hemisphere_dicts:\n",
    "    print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
